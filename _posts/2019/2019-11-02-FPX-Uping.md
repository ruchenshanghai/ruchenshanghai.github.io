---
layout: post
title: FPX is Uping
---

Deep learning with FPX uping

![alt text]({{ site.baseurl }}/images/2019/11/smoking-in-dress.jpg "image alt"){: .center-image }
Frequentist estimators, Bayesian inference, supervised/unsupervised learning, stochastic gradient descen.\
Example, feature, classification, classification with missing inputs, regression, transcription, machine translation, structured output, anomaly detection, synthesis and sampling, imputation of missing values, denoising, density estimation/probability mass function estimation.\
Performance measure: accuracy, error rate, 0-1 loss, test set.\
Experience, dataset, design matrix.\
Linear regression, parameters, mean squared error, normal equations.\
Generalization, training error, generalization error/test error, statistical learning theory, data generating process, i.i.d. assumptions, independent and identically distributed, data generating distribution, underfitting, overfitting, capacity, hypothesis space, representational capacity, effective capacity, Occam's razor, Vapnik-Chervonenkis dimension/VC dimension, underfitting regime, overfitting regime, optimal capacity, non-parametric models, nearest neighbor regression, Bayes error.\
The no free launch theorem.