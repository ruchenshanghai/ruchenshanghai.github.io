---
layout: post
title: New Direction
---

You just look like gentle.

MP神经元，净输入，净活性值，活性值，激活函数。\\
Sigmoid 激活函数：Logistic 函数，偏移偏置，Tanh 函数，零中心化。Hard，Taylor expansion。\\
ReLU 函数，rectified linear unit，修正线性单元，非零中心化 偏置偏移。死亡 Dying ReLU，带泄露的 Leaky ReLU，带参数的 Parametric ReLU，指数线性单元 ELU，Softplus 函数，Swish 函数 自门控，GELU 高斯误差线性单元，Maxout 单元。\\
网络结构：前馈网络，记忆网络（记忆增强），图网络（图卷积，图注意力，消息传递）。\\
通用近似定理 Universal Approximation Theorem，Frobenius 范数，反向传播算法。